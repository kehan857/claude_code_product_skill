#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GLMæ¨¡å‹è°ƒç”¨Skill
å¯ä»¥ç›´æ¥è°ƒç”¨æ™ºè°±AIçš„GLMæ¨¡å‹è¿›è¡Œå¯¹è¯å’Œåˆ†æ
"""

import os
import sys
import json

try:
    from zhipuai import ZhipuAI
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£…zhipuaiåº“: pip install zhipuai")
    sys.exit(1)

# GLM APIé…ç½®
GLM_API_KEY = "b3711c0052914e28abfa035b70e0e59e.Q7gu5Sb6tdILkCsk"

# é»˜è®¤é…ç½®
DEFAULT_MODEL = "glm-4-flash"  # ä½¿ç”¨å¿«é€Ÿä¸”ç»æµçš„æ¨¡å‹
DEFAULT_TEMPERATURE = 0.7
DEFAULT_MAX_TOKENS = 2000

class GLMSkill:
    """GLMæ¨¡å‹è°ƒç”¨æŠ€èƒ½ç±»"""

    def __init__(self, api_key=None):
        """åˆå§‹åŒ–GLMå®¢æˆ·ç«¯"""
        self.api_key = api_key or GLM_API_KEY
        self.client = ZhipuAI(api_key=self.api_key)

    def chat(self, message, system_prompt=None, model=None, temperature=None, max_tokens=None):
        """
        ä¸GLMæ¨¡å‹å¯¹è¯

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            model: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šglm-4-flashï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼ˆé»˜è®¤ï¼š0.7ï¼‰
            max_tokens: æœ€å¤§tokenæ•°ï¼ˆé»˜è®¤ï¼š2000ï¼‰

        Returns:
            str: æ¨¡å‹å“åº”
        """
        try:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": message})

            # è°ƒç”¨GLM API
            response = self.client.chat.completions.create(
                model=model or DEFAULT_MODEL,
                messages=messages,
                temperature=temperature or DEFAULT_TEMPERATURE,
                max_tokens=max_tokens or DEFAULT_MAX_TOKENS,
            )

            # è¿”å›ç»“æœ
            result = response.choices[0].message.content

            # æ˜¾ç¤ºtokenä½¿ç”¨æƒ…å†µ
            usage = response.usage
            print(f"\nğŸ“Š Tokenä½¿ç”¨: {usage.total_tokens} (è¾“å…¥: {usage.prompt_tokens}, è¾“å‡º: {usage.completion_tokens})")

            return result

        except Exception as e:
            return f"âŒ è°ƒç”¨å¤±è´¥: {str(e)}"

    def analyze_product(self, product_info):
        """åˆ†æäº§å“"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº§å“ç»ç†å’Œäº§å“åˆ†æå¸ˆï¼Œæ“…é•¿ï¼š
1. å¸‚åœºåˆ†æå’Œç«å“ç ”ç©¶
2. ç”¨æˆ·éœ€æ±‚åˆ†æ
3. äº§å“åŠŸèƒ½è®¾è®¡
4. æ•°æ®æŒ‡æ ‡åˆ¶å®š
5. äº§å“è§„åˆ’å»ºè®®

è¯·ä»¥ä¸“ä¸šã€å®¢è§‚çš„è§’åº¦è¿›è¡Œåˆ†æï¼Œç»™å‡ºå…·ä½“å¯è¡Œçš„å»ºè®®ã€‚"""

        message = f"""è¯·åˆ†æä»¥ä¸‹äº§å“ï¼š

{product_info}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œåˆ†æï¼š
1. å¸‚åœºå®šä½ä¸ç›®æ ‡ç”¨æˆ·
2. æ ¸å¿ƒç«äº‰ä¼˜åŠ¿
3. åŠŸèƒ½å»ºè®®
4. æ•°æ®æŒ‡æ ‡å»ºè®®
5. é£é™©ä¸åº”å¯¹"""

        return self.chat(message, system_prompt)

    def generate_product_doc(self, product_name, description):
        """ç”Ÿæˆäº§å“æ–‡æ¡£"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„äº§å“æ–‡æ¡£ç¼–å†™ä¸“å®¶ï¼Œç†Ÿæ‚‰äº§å“è¯¦ç»†è®¾è®¡æ–‡æ¡£çš„ç¼–å†™è§„èŒƒã€‚
æ–‡æ¡£åº”è¯¥ç¬¦åˆä¸­æ–‡å­¦æœ¯æ ¼å¼ï¼ŒåŒ…æ‹¬ï¼š
- äº§å“æ¦‚è¿°
- å¸‚åœºåˆ†æ
- ç”¨æˆ·åˆ†æ
- äº§å“åŠŸèƒ½
- åŠŸèƒ½è¯¦ç»†è®¾è®¡
- æ•°æ®æŒ‡æ ‡
- è¿è¥è§„åˆ’
- é£é™©ä¸åº”å¯¹
- äº§å“è·¯çº¿å›¾"""

        message = f"""è¯·ä¸ºä»¥ä¸‹äº§å“ç”Ÿæˆè¯¦ç»†è®¾è®¡æ–‡æ¡£å¤§çº²ï¼š

äº§å“åç§°ï¼š{product_name}
äº§å“æè¿°ï¼š{description}

è¯·ç”Ÿæˆå®Œæ•´çš„äº§å“è¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼ŒåŒ…å«ä¹å¤§æ ¸å¿ƒæ¨¡å—ã€‚"""

        return self.chat(message, system_prompt, max_tokens=4000)

    def improve_requirement(self, requirement_text):
        """ä¼˜åŒ–éœ€æ±‚æè¿°"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªäº§å“éœ€æ±‚åˆ†æä¸“å®¶ï¼Œæ“…é•¿å°†æ¨¡ç³Šçš„éœ€æ±‚è½¬åŒ–ä¸ºæ¸…æ™°ã€å¯æ‰§è¡Œçš„äº§å“éœ€æ±‚ã€‚
ä½ ä¼šï¼š
1. ç†è§£ç”¨æˆ·çš„æ ¸å¿ƒè¯‰æ±‚
2. è¯†åˆ«éœ€æ±‚ä¸­çš„å…³é”®ç‚¹
3. è¡¥å……ç¼ºå¤±çš„ä¿¡æ¯
4. ä¼˜åŒ–éœ€æ±‚è¡¨è¾¾
5. ç»™å‡ºå¯è¡Œæ€§å»ºè®®"""

        message = f"""è¯·å¸®æˆ‘ä¼˜åŒ–ä»¥ä¸‹éœ€æ±‚æè¿°ï¼š

{requirement_text}

è¯·æä¾›ï¼š
1. éœ€æ±‚åˆ†æ
2. ä¼˜åŒ–åçš„éœ€æ±‚æè¿°
3. éœ€æ±‚æ‹†è§£ï¼ˆå¦‚æœæœ‰å¤šä¸ªå­éœ€æ±‚ï¼‰
4. å®ç°å»ºè®®"""

        return self.chat(message, system_prompt)


def main():
    """ä¸»å‡½æ•°ï¼šå‘½ä»¤è¡Œäº¤äº’"""
    print("=" * 60)
    print("ğŸ¤– GLMæ¨¡å‹è°ƒç”¨Skill")
    print("=" * 60)

    # åˆå§‹åŒ–GLM Skill
    glm = GLMSkill()

    print("\nè¯·é€‰æ‹©åŠŸèƒ½ï¼š")
    print("1. ğŸ’¬ æ™®é€šå¯¹è¯")
    print("2. ğŸ“Š äº§å“åˆ†æ")
    print("3. ğŸ“ ç”Ÿæˆäº§å“æ–‡æ¡£")
    print("4. âœ¨ ä¼˜åŒ–éœ€æ±‚æè¿°")
    print("5. ğŸšª é€€å‡º")

    while True:
        choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-5): ").strip()

        if choice == "1":
            # æ™®é€šå¯¹è¯
            message = input("è¯·è¾“å…¥ä½ çš„æ¶ˆæ¯: ").strip()
            if message:
                response = glm.chat(message)
                print(f"\nğŸ¤– GLMå›å¤:\n{response}\n")

        elif choice == "2":
            # äº§å“åˆ†æ
            print("\nè¯·è¾“å…¥äº§å“ä¿¡æ¯ï¼ˆè¾“å…¥å®ŒæˆåæŒ‰å›è½¦ï¼‰ï¼š")
            product_info = input().strip()
            if product_info:
                response = glm.analyze_product(product_info)
                print(f"\nğŸ“Š äº§å“åˆ†æ:\n{response}\n")

        elif choice == "3":
            # ç”Ÿæˆäº§å“æ–‡æ¡£
            product_name = input("è¯·è¾“å…¥äº§å“åç§°: ").strip()
            description = input("è¯·è¾“å…¥äº§å“æè¿°: ").strip()
            if product_name and description:
                response = glm.generate_product_doc(product_name, description)
                print(f"\nğŸ“ äº§å“æ–‡æ¡£:\n{response}\n")

        elif choice == "4":
            # ä¼˜åŒ–éœ€æ±‚
            print("\nè¯·è¾“å…¥éœ€æ±‚æè¿°ï¼ˆè¾“å…¥å®ŒæˆåæŒ‰å›è½¦ï¼‰ï¼š")
            requirement = input().strip()
            if requirement:
                response = glm.improve_requirement(requirement)
                print(f"\nâœ¨ ä¼˜åŒ–åçš„éœ€æ±‚:\n{response}\n")

        elif choice == "5":
            print("\nğŸ‘‹ å†è§ï¼")
            break

        else:
            print("\nâŒ æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°è¾“å…¥")


if __name__ == "__main__":
    # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œç›´æ¥å¤„ç†
    if len(sys.argv) > 1:
        glm = GLMSkill()

        if sys.argv[1] == "chat" and len(sys.argv) > 2:
            # ç›´æ¥å¯¹è¯
            message = " ".join(sys.argv[2:])
            response = glm.chat(message)
            print(response)

        elif sys.argv[1] == "analyze" and len(sys.argv) > 2:
            # åˆ†æäº§å“
            product_info = " ".join(sys.argv[2:])
            response = glm.analyze_product(product_info)
            print(response)

        elif sys.argv[1] == "doc" and len(sys.argv) > 3:
            # ç”Ÿæˆæ–‡æ¡£
            product_name = sys.argv[2]
            description = " ".join(sys.argv[3:])
            response = glm.generate_product_doc(product_name, description)
            print(response)

        else:
            print("ç”¨æ³•:")
            print("  python glm_skill.py chat <æ¶ˆæ¯>")
            print("  python glm_skill.py analyze <äº§å“ä¿¡æ¯>")
            print("  python glm_skill.py doc <äº§å“åç§°> <äº§å“æè¿°>")
            print("  python glm_skill.py  # äº¤äº’æ¨¡å¼")
    else:
        # äº¤äº’æ¨¡å¼
        main()
