#!/bin/bash
# GLMæ¨¡å‹è°ƒç”¨è„šæœ¬ï¼ˆShellç‰ˆæœ¬ï¼‰
# ä½¿ç”¨æ–¹æ³•: ./glm_chat.sh "ä½ çš„æ¶ˆæ¯"

GLM_API_KEY="b3711c0052914e28abfa035b70e0e59e.Q7gu5Sb6tdILkCsk"
GLM_MODEL="glm-4-flash"
GLM_API_URL="https://open.bigmodel.cn/api/paas/v4/chat/completions"

# é»˜è®¤æ¶ˆæ¯
MESSAGE=${1:-"ä½ å¥½"}

# è°ƒç”¨GLM API
curl -s -X POST "$GLM_API_URL" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $GLM_API_KEY" \
  -d "{
    \"model\": \"$GLM_MODEL\",
    \"messages\": [
      {\"role\": \"user\", \"content\": \"$MESSAGE\"}
    ],
    \"temperature\": 0.7,
    \"max_tokens\": 2000
  }" | python3 -c "
import sys, json
try:
    data = json.load(sys.stdin)
    if 'choices' in data and len(data['choices']) > 0:
        content = data['choices'][0]['message']['content']
        print(content)
        if 'usage' in data:
            print(f\"\nğŸ“Š Tokenä½¿ç”¨: {data['usage']['total_tokens']}\", file=sys.stderr)
    else:
        print('âŒ APIè¿”å›æ ¼å¼å¼‚å¸¸', file=sys.stderr)
        print(json.dumps(data, indent=2, ensure_ascii=False), file=sys.stderr)
except Exception as e:
    print(f'âŒ è§£æå“åº”å¤±è´¥: {e}', file=sys.stderr)
"
